{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "KMeans Clustering"
      ],
      "metadata": {
        "id": "CsvLrbDMV97W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import json\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "kH5Got1dWAno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fuFCYG9Z1PG",
        "outputId": "d10f5221-4c3a-4203-cffa-e7d3d2727007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/data set/wheetseeds.csv').to_numpy()[:,:-1]"
      ],
      "metadata": {
        "id": "QbN8KLucjo6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pseudocode tolad Load data from file and save in the numpy matrix.\n",
        "You can use panda to read the dataset in to numpy matrix. data matrix will have data points. First column is point index. Rest of the columns have features.  ClassLabel has the labels."
      ],
      "metadata": {
        "id": "QMeWajTXWF0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def load(file_name):\n",
        "#     # data(2D list or list of list): [[ . . .4 dimensions . . .], [..., ...], ...]\n",
        "#     temp=[]\n",
        "#     data = []\n",
        "#     classLabel = []\n",
        "#     fh = open(file_name)\n",
        "#     for line in fh:\n",
        "#         line = line.strip().split(',')\n",
        "#         for feature in line[0:-2]:\n",
        "#             temp.append(feature)\n",
        "#         classLabel.append(line[-1])\n",
        "#         data.append(temp)\n",
        "#     data = np.array(data)  #Numpy data matrix,\n",
        "#     return data, classLabel#classLabel contains class label"
      ],
      "metadata": {
        "id": "RkLX9kQDWMLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple centroid initialization function"
      ],
      "metadata": {
        "id": "RvgJK_f_WOlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_centroids_simple(data, dimension, k):\n",
        "    #centroids: [[centroid0:  3 dimensions, , , ]; [centroid1: 3 dimensions ] ... ..]\n",
        "    centroids = np.array([[0 for _ in range(dimension)] for _ in range(k)])\n",
        "    #TO DO\n",
        "    np.random.shuffle(data)\n",
        "    rows = data[:k, :]\n",
        "    centroids = rows\n",
        "    #Write your code to return initialized centroids by randomly assiging them to K points\n",
        "    return centroids"
      ],
      "metadata": {
        "id": "xZm_BPcEWTlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Centroid initilization using min max"
      ],
      "metadata": {
        "id": "ZLyNeHzdWnTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def initialize_centroids(data, dimension, k):\n",
        "#     centroids = np.array([[0 for _ in range(dimension)] for _ in range(k)])\n",
        "#     max_feature_vals =  np.array([0 for _ in range(dimension)])\n",
        "#     min_feature_vals =  np.array([float('inf') for _ in range(dimension)])\n",
        "#     # TO DO\n",
        "#     # Calculate max feature and min feture value for each dimension\n",
        "#     #diff: max - min for each dimension\n",
        "#     # for each centroid, in each dimension assign centroids[j][i] = min_feature_val + diff * random.uniform(1e-5, 1)\n",
        "#     return centroids"
      ],
      "metadata": {
        "id": "W5Bkn0OwWvR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate eucledian distance"
      ],
      "metadata": {
        "id": "J3vAsctEWwYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_euclidean_distance(p1, p2):\n",
        "    distance = -1.0\n",
        "    distance = np.linalg.norm(p1 - p2)\n",
        "    return distance"
      ],
      "metadata": {
        "id": "VfZobkk-W2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "print(np.array([-1 for _ in range(0, N)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSJmotBzCjvR",
        "outputId": "92ac5399-726e-43cd-ba43-47fdf33329d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans Function\n"
      ],
      "metadata": {
        "id": "YvA2jiqiXBvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans(data, dimension, k):\n",
        "    N = np.size(data, 0)\n",
        "    #centroids: [[centroid0:  , , ,3 dimensions, , , ]; [centroid1: , , ,3 dimensions, , , ] ... ..]\n",
        "    centroids = initialize_centroids_simple(data, dimension, k)\n",
        "    #cluster_affiliation: cluster_affiliation = [clusternumber, clutsernumber, ..., ..., ..., ...]\n",
        "    flag = 1\n",
        "    #initialize the cluster affiliations. Initially assign -1\n",
        "    cluster_affiliation = np.array([-1 for _ in range(0, N)])\n",
        "    while flag:\n",
        "       centroids = new_centroids\n",
        "       for i, point in enumerate(data):\n",
        "            min_distance = float('inf')\n",
        "            min_distance_index = None\n",
        "\n",
        "            #find closest centroids for each data points\n",
        "            for cluster_index, centroid in enumerate(centroids): #use numpy equivalent code\n",
        "                distance = get_euclidean_distance(centroid, point)\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    min_distance_index = cluster_index\n",
        "\n",
        "            #record or update cluster for each data points\n",
        "            if cluster_affiliation[i] != min_distance_index:\n",
        "               cluster_affiliation[i] = min_distance_index\n",
        "\n",
        "       #recompute centroids\n",
        "       new_centroids = np.array([[0 for _ in range(dimension)] for _ in range(k)]) # new centroids initialized with 0\n",
        "       cluster_point_count = np.array([0 for _ in range(k)]) #keep number of points for each cluster. You should use\n",
        "       #cluster_affiliation  to calculate it\n",
        "       #TO DO\n",
        "       #write your code to count each cluster pointcount and store them in clutser_point_count structure\n",
        "       cluster_array = [[] for _ in range(k)]\n",
        "       for i in range(N):   # make saparation by diff cluster\n",
        "         cluster_point_count[cluster_affiliation[i]] += 1\n",
        "         cluster_array[cluster_affiliation[i]].append(data[i])\n",
        "       #recompute centroids using the count\n",
        "       for i in range(len(cluster_array)):    # update it's centroids\n",
        "         new_centroids[i] = np.divide(np.sum(cluster_array[i], axis = 0),cluster_point_count[i])\n",
        "       for i in range(k):\n",
        "         if get_euclidean_distance(new_centroids[i],centroids[i])<0.00005:\n",
        "           flag = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #TO DO ?\n",
        "    #Terminate the while loop based on termination criteria. Write your code to turn flag = false\n",
        "    return (centroids, cluster_affiliation)\n"
      ],
      "metadata": {
        "id": "G-5U2bt-XI8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q_5_E . In the main function, draw a 3D plot where**"
      ],
      "metadata": {
        "id": "VIu9_SPEUSR2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySpRtDyKURrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver funtion/Main Function"
      ],
      "metadata": {
        "id": "XduHk-N0XKQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "# \tstart = time.time()\n",
        "\n",
        "#   #input path of the real data\n",
        "#   #data file contains point index, 4 features, and class label in each line separated by comma\n",
        "# \t# inputpath =  'C:/Users/LENOVO\\Dropbox/IUB - DataMining/Assignments/BFRClustering/clustering-master/clustering-master/test2'\n",
        "\n",
        "K = 4 # K clusters\n",
        "\n",
        "# \t# inputfilename = inputpath + '/data' + str(data_num) + '.txt'\n",
        "# \t# data = load(\"/content/drive/MyDrive/dataset/wheetseeds.txt\")\n",
        "dimension = np.size(data, 1)# number of  data dimension\n",
        "#   print(dimension)\n",
        "\n",
        "# centroids, cluster_affiliation = kmeans(data, dimension, K)\n",
        "# \t#TODO\n",
        "#   #Write all final centroids in out1 file. one line for each centroids, Features would separted by ,\n",
        "#   #in out2, Write the cluster assignments for each of the point. Each line: Point index, cluster number\n",
        "\n",
        "\n",
        "# \tprint('Duration: %s' % (time.time() - start))\n",
        "# print(centroids, cluster_affiliation)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EdutF8_91Wq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}